#### Response to Reviewer #1



"The idea of using it (barriers) for NMT reranking actually does not use..."

Yes, as you noticed, the reranking candidates is not generated by editing the barrier words, since we haven't come up with a method for detecting barriers without knowing the reference yet. Actually, it is the discovery of barrier words (we can generate much better translation candidates by editing one single source words) that motivates us to propose to edit **every** source words with certain amount of random tokens in the vocabulary to generate better oracle candidates for reranking.



"More explanation is wanted for context-aware and model-aware and previous methods are not."

Previous methods are based on global statistics like word frequency, translation entropy (obtained from IBM model, instead of the NMT model), so the rank of every two word is fixed no matter what specific sentence they co-occurs in, therefore, we call those words model-agnostic/context-agnostic or global troublemakers. However, in our definition of generalization barriers, it is highly context-dependent, since for NMT, not like the IBM model family assuming factorization of translation probability, the input words/phrases's representations are highly entangled by the encoder, this might be one reason for the context-sensitivity of the detected barrier words.



We will fix other typos in the next revised version. Thanks for all the advices, we really appreciated them!



#### Response to Reviewer #2

"The collected words may be biased and noisy. There are no discussion whether the collected words are representative"

Definition 3.1 of barrier words **ensures** that those words are the cause of performance degradation on a certain input x, since by modifying it, the performance will witness significant boost w.r.t. human evaluator, which actually meets the representativeness principle in your comment. Since it is very expensive for asking human to edit and judge improvement, we have to carefully adopt automatic metrics (like sentence-BLEU) for large-scale analysis. We have to admit the detection might be biased due to the inconsistency between BLEU and human evaluation. We think it is the current dilemma of automatic evaluation metrics in general. So we make a compromise here by trading analysis scale with detection bias. Although the detection results  might be biased due to mismatch with human evaluator, at least if you believe in BLEU, you can take the risk to accept the rationale of the analysis.



"Unknown words like rare named entities..."

We appreciate your concern on rare named entities. In our POS analysis, we find that actually for Nouns and Proper Nouns which contains named entities, they are less likely to cause translation performance degradation (Table 2). One point to clarify here is that, our definition (3.1) do not cover those source words that is itself not well-translated, but those source words, due to their existence, becoming the cause of mis/under-translation of other source words or hinder the overall generalization of this instance.



"The usage of the word 'generalization' seems to be strange"

Generalization is the ability of a trained model to generalize on unseen data, it should be tested on held-out data. Training data is one factor that determines its generalization ability (together with inductive bias of the model, optimization and so on), but we should not use training data for understanding model's weakness and crispness of generalization. So we think it is proper for naming those tokens in held-out sentences as generalization barriers. If you focus on detecting tokens with training data, it is to test the **fitting/memorization** ability (not the generalization) ability of the trained model, since the model has already seen those data and might have memorized the ground-truth mapping.



"Definition 3.1 is vague."

We would like to clarify that a principled definition is not necessary a formal definition with mathematical instantiation of every details, but a definition that is convincing and make the underlying concept acceptable and general enough. Our principled definition leave it open how much one can perform editing on the original badly-generalized instance x, and satisfactory-level is determined by end user.



#### Response to Reviewer #3

"the method relies on human to improve performance"

The main purpose of this paper is to detect the so-called generalization barrier words for better understanding the current weakness and crispness of NMT model at a very fine-grained level of causality. We think it is the most important issue of current large-scale supervised NMT systems, that is, corpus-level BLEU is uninformative for us to find problems. Instead of just telling the average corpus BLEU score, we can analyze what on earth cause the NMT model to perform poor on a specific instance. So we propose two definitions of generalization barriers, and used the approximate definition which **does not** involve human effort for automatic detection of barriers.

Our initial purpose is not to propose specific strategies for improving translation performance, but to characterize how and why the model perform poor on some test instances, though one potential usage such as modifying the source for generating better re-ranking candidates is derived. Disclaimer, we haven't try the reranking idea yet, instead, we prove its effectiveness by reporting much better oracle BLEU than traditional ways of generating candidates.



"hard to evaluate the contribution of the work"

We think the most valuable information of our work is that: current large-scale supervised NMT systems are very good at generalization already, since tiny modification (without change of its meaning) of the input can improve translation much better. 

