---
layout: post
title: "Interpretability in Computer Vision and Natural Language Processing"
author: Reading group members
tag: redmond_rg
---

Interpretability in CV:
- [Evaluating the visualization of what a Deep Neural Network has learned](https://arxiv.org/pdf/1509.06321.pdf), Layer-wise Relevance Propagation techniques, better than sensitivity and deconvolution methods. 
- [Interpreting CNN Knowledge Via An Explanatory Graph](https://arxiv.org/pdf/1708.01785.pdf), AAAI 2018. Songchun Zhu's group. 
- [Interpretable CNN](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.pdf), CVPR 2018, Songchun Zhu's group. 
- [Network Dissection: Quantifying Interpretability of Deep Visual Representations](https://arxiv.org/abs/1704.05796), TPAMI 2018. Bolei Zhou's work. 

Interpretability in NLP, all papers from Gramham Neubig's group: 
- [Multi-space Variational Encoder-Decoders](http://www.phontron.com/paper/zhou17acl.pdf), ACL 2017. 
- [StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing (acl. 18)](http://aclweb.org/anthology/P18-1070), ACL 2018. [code](https://github.com/pcyin/structvae). 
- [Unsupervised Learning of Syntactic Structure w/ Invertible Neural Projections](http://aclweb.org/anthology/D18-1160), EMNLP 2018. [code](https://github.com/jxhe/struct-learning-with-flow).
- [Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement](http://aclweb.org/anthology/P18-1032), ACL 2018. 
