<html lang='en'>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!--<title>Variational Posterior Estimation via GANs: Bayesian Logistic Regression As Showcase</title>-->
    <title>Guanlin Li</title>
    <link href="https://fonts.googleapis.com/css?family=Droid+Sans+Mono" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
    <link href="/public/css/bootstrap.min.css" rel="stylesheet">
    <link href="/public/css/github.css" rel="stylesheet">
    <style>
        hr {
            height: 1px;
        }
        footer {
            font-family: "Noto Sans", "Arial", sans-serif;
            margin-top: 50px;
        }
        img {
            margin-left: auto;
            margin-top: auto;
            margin-bottom: auto;
            margin-right: auto;
            max-width:90%;
            max-height:90%;
        }
        img.center {
            margin-left: auto;
            margin-right: auto;
            padding-bottom: 50px;
            padding-top: 50px;
            max-width:90%;
            max-height:90%;
            display: block;
        }
        p {
            line-height: 1.5; margin-top: 15px; margin-bottom: 15px;
        }
    </style>
</head>


<body style="font-size: 16px;">

<nav class="navbar navbar-default" style="display: block; font-size: 18px;" role="navigation">
    <div class="container col-lg-8 col-lg-offset-2">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-data" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/" style="padding-left: 30px">Guanlin Li</a>
        </div>


        <div id="navbar-data" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <!--li>
                    <a href="/" style="padding-left: 30px">Home</a>
                </li-->
                <li>
                    <a href="/blog" style="padding-left: 30px">Articles</a>
                </li>
                <li>
                	<a href="/party" style="padding-left: 30px">Evening Tea Party</a>
                </li>
                <!--li>
                    <a href="/projects" style="padding-left: 30px">Projects</a>
                </li-->
                <!--li>
                    <a href="/reading" style="padding-left: 30px">Reading</a>
                </li-->
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="https://github.com/epsilon-lee" target="_blank" style="padding-left: 30px"><img src="/public/img/icon/github.min.svg" height="24px" width="24px"></a>
                </li>
                <li>
                    <a href="https://twitter.com/Epsilon_Lee" target="_blank" style="padding-left: 30px"><img src="/public/img/icon/twitter.min.svg" height="24px" width="24px"></a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/guanlin-li-762830143/" target="_blank" style="padding-left: 30px"><img src="/public/img/icon/linkedin.min.svg" height="24px" width="24px"></a>
                </li>
                <!--<li>
                    <a href="/static/jiaming_cv.pdf" target="_blank" style="padding-left: 30px">Curriculum Vitae</a>
                </li>-->
            </ul>
        </div>
    </div>
</nav>


<div class="container" style="margin-top: 50px;">
<div class="row">
<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-10 col-sm-offset-1">
      
      <h2>Variational Posterior Estimation via GANs: Bayesian Logistic Regression As Showcase</h2>
      <!--h5>by Guanlin Li </h5-->
      <!--hr/-->
      
      <blockquote>
  <p>I will start concise presentations of works done by others through exploratory, experimentary practice. This blog is a based on a start of <strong>Ferenc Huszar</strong>’s series <a href="http://www.inference.vc/variational-inference-with-implicit-probabilistic-models-part-1-2/">blogs</a>. His blogs continually demonstrates the use of GANs as a learning mechanism for implicit generative models, such as a variational distribution defined implicitly by a neural network for easy sampling and posterior inference. Personally, I want to thank Ferenc a lot, since his blogs is my source of intuitions on the way to learn and interpret probabilistic generitive modelling, variational methods and GANs. I wish to see his continual updates of his Blog.</p>
</blockquote>

<h3 id="exploratory-problem">Exploratory Problem</h3>

<p>The problem is kept simple and concise for exploration as a beginner. It is <strong>Bayesian Logistic Regression (BLR)</strong>, the traditional logistic regression formulation augmented with prior on weight <script type="math/tex">w</script>.</p>

<p>So let us first restate the Bayesian formulation of logistic regression. <strong>BLR</strong> can be depicted as the above graphical model. <script type="math/tex">x_n</script> is the feature vector of a sample point, <script type="math/tex">y_n</script> is its corresponding label, <script type="math/tex">y_n \in \{0,1\}</script>. For the convenience of visualization, I will set that <script type="math/tex">x_n \in \mathbb{R^2}</script>. For every sample point, the probability of its label is defined as:</p>

<script type="math/tex; mode=display">P(y_n \vert w; x_n, b) = p_i^{1[y_n=1]} (1-p_i)^{1[y_n=0]}</script>

<p><script type="math/tex">1[\cdot]</script> is the indicator function, where</p>

<script type="math/tex; mode=display">p_i = \frac{1}{1 + \exp(-b - w^T x_n)}</script>

<p><script type="math/tex">p_i​</script> is the logistic sigmod function value of <script type="math/tex">(-b-\mathbb{w}^T x_n)​</script>. To clarify notation, <script type="math/tex">P(\cdot)​</script> is used as a probability (measure) operator, the vertical bar <script type="math/tex">\vert ​</script> means that the expression before is conditioned on the after; and the colon ‘;’ means expressions after are seen as constant. See the following comment.</p>

<blockquote>
  <p><strong>Comment</strong> More words on the notations. In the book Pattern Recognition and Machine Learning (PRML), every expressions which have the semantic meaning ‘observed’/’given’/’conditioned on’ are after vertical bar <script type="math/tex">\vert</script>. E.g. <script type="math/tex">p(t\vert\pi, \mathbb{\mu_1}, \mathbb{\mu_2}, \mathbb{\Sigma})</script>, here we don’t know whether <script type="math/tex">\pi, \mathbb{\mu_1}, \mathbb{\mu_2}, \mathbb{\Sigma}</script> are seen as random variables or not as within Bayesian context. In the book Pattern Classification, the notation is consistent with PRML. In Machine Learning: A Probabilistic Perspective (MLaPP), the definition of logistic regression model is: <script type="math/tex">p(y \vert x, \mathbb{w}) = Ber(y \vert sigm(\mathbb{w}^T x))</script>, whereas in PRML is: <script type="math/tex">p(t \vert \mathbb{w}) = y_n^{t_n} \{ 1-y_n \}^{1-t_n}</script>, where <script type="math/tex">y_n = p(\mathcal{C}_1 \vert \phi_n)</script> and <script type="math/tex">\phi_n = \phi(x_n)</script>. As for MLaPP, it is not clear whether $ x $ is seen as a random variable or not, and both books tacle with Bayesian approach towards logistic regression later on. To be more clarified, I would like to propose the use of colon $ ; $ symbol, and the conditional probability will always have the following form: <script type="math/tex">P(\cdot \vert \cdot ; \cdot)</script>. We always see expressions after <script type="math/tex">\vert</script> and before ; as r.v.s and expression after ; as constants. This leads to the expression in our first equation, i.e. <script type="math/tex">P(y_n \vert \mathbb{w}; x_n, b)</script>. And in <script type="math/tex">\mathcal{N}(x; \mathbb{\mu}, \mathbb{\Sigma})</script>, <script type="math/tex">\mathbb{\mu}</script> and <script type="math/tex">\mathbb{\Sigma}</script> are not seen as r.v.s.</p>
</blockquote>

<p>The so-called Bayesian is that we put prior knowledge on the value of <script type="math/tex">w</script>. Specifically, we assume a Bivariate Gaussian distribution:</p>

<script type="math/tex; mode=display">P(w) = \mathcal{N}(0, \sigma^2 \mathbb{I}_2) = \frac{1}{2 \pi} \frac{1}{\sigma} \exp \{ - \frac{\vert \vert x \vert \vert^2}{2\sigma^2} \}</script>

<p>Since we know Multivariate Gaussian is:</p>

<script type="math/tex; mode=display">\mathcal{N}(x;\mathbb{\mu}, \mathbb{\Sigma}) = \frac{1}{(2\pi)^{D/2}} \frac{1}{\vert \mathbb{\Sigma} \vert ^{1/2}} exp\{ -\frac{1}{2} (x - \mathbb{\mu})^T \Sigma^{-1} (x - \mathbb{\mu}) \}</script>

<p>Here, the assumed distribution on <script type="math/tex">\mathbb{w}</script> is <strong>spherical Gaussian</strong> with diagnal covariance matrix. We can go on to write down the probability of the data set <script type="math/tex">\mathcal{D}</script> given we know the <script type="math/tex">\mathbb{w}</script>, that is <script type="math/tex">P(\mathcal{D} \vert \mathbb{w}; b)</script>. And <script type="math/tex">\mathcal{D}</script> stands for the <script type="math/tex">\{ (x_n, y_n)_{n=1}^{N} \}</script>. We have:</p>

<script type="math/tex; mode=display">P(\mathcal{D} \vert w; b) = P(\{y_n\}_{n=1}^{N} \vert w; \{x_n\}_{n=1}^{N}, b)</script>

<p>This is called the likelihood of the data under the model parameterized by <script type="math/tex">\mathbb{w}</script>. We want to perform posterior inference on this parameter, that is to derive a computational form of <script type="math/tex">P(\mathbb{w}  \vert \mathcal{D} )</script>. We know posterior estimation is not point estimation but density/distribution estimation. We use Bayes formula to get:</p>

<script type="math/tex; mode=display">P(\mathbb{w} \vert \mathcal{D}) = \frac{ P(\mathcal{D} \vert w) P(w)}{ P(\mathcal{D}) } = \frac{ P(\mathcal{D} \vert w) P(w)}{ \int_{\mathbb{w}} d\mathbb{w} P(\mathcal{D} \vert w) P(w) }</script>

<p>Very different from Maximum Likelihood Estimation (MLE), to which the computational issue is optimization (maximazing log-likelihood function of data), Bayesian inference or posterior estimation is solving an intractable intergal. Traditional ways of preventing intractability is to restrict prior and posterior to be conjugated, preserve exactability whereas introduce limitations of expressibility. In this blog, we resort to one popular approximation method - Variational Inference which uses a tractable (easy to sample from), parameterized distribution to approximate the real one by minimizing their KL divergence:</p>

<script type="math/tex; mode=display">KL(Q \vert \vert P) = \int_{\mathbb{w}} Q log \frac{Q}{P}</script>

<p>where <script type="math/tex">P</script> stands for  <script type="math/tex">P(w  \vert\mathcal{D})</script>. In next section, I will derive a form of this KL divergence and show how to parameterize <script type="math/tex">Q</script> so we can simultaneously minimize KL and preserve expressibility of <script type="math/tex">Q</script>.</p>

<p>Before diving into math, I have confused with another question about this variational inference objective - KL divergence.</p>

<blockquote>
  <p>Since we know KL divergence is not symmetric for the two compared distributions, so <strong>WHY</strong> use <script type="math/tex">KL(Q \vert \vert P)</script> instead of <script type="math/tex">KL(P \vert \vert Q)</script>?</p>
</blockquote>

<h3 id="math-derivation">Math Derivation</h3>

<p>Let us now do some deduction on the KL divergence formula and see what we could get. And to understand why should we use <script type="math/tex">Q \vert \vert P</script> instead of <script type="math/tex">P \vert \vert Q</script>. In variational inference, we usually parameterize distribution Q, here the only assumption is we use parametric method instead of non-parametric to model Q and the parameters of Q are denoted as <script type="math/tex">\theta_Q</script>. So we can make the parameter <script type="math/tex">\theta_Q</script> explicit in the KL term, i.e. <script type="math/tex">KL(Q \vert\vert P; \theta_Q)</script>.</p>

<p>Now, let us try to interpret the objective function. It has two terms: <strong>a).</strong> KL divergence between approximation <script type="math/tex">Q</script> and prior <script type="math/tex">P(\mathbb{w})</script>, which is a spherical Gaussian. <strong>b).</strong> The <strong>EXPECTED</strong> negative <u>log-likelihood of the data set</u> w.r.t. to <script type="math/tex">\mathbb{w}</script> sampled from the approximation distribution. To minimize this <script type="math/tex">\mathcal{O}(\theta_Q)</script> is to find an approximation distribution Q on <script type="math/tex">\mathbb{w}</script> which maximize the expected likelihood while does not make Q too far from the prior (our prior knowledge as a regularization).</p>

<p>So how to solve this optimization problem? Let us use the simple but powerful gradient descent (GD), unless we can analytically derive the solution by computing the gradient and set it to 0.</p>

<p>Traditionally, Q is defined within a tractable family of distribution, e.g. exponential family, mixture of Gaussians etc. (TO-DO: derive and implement a traditional version). The reason for restricting Q is: 1). Easily sample from Q, so we can ease this optimization. That is, we can easily compute approximate gradient by monte carlo methods and do GD. 2). […].</p>

<blockquote>
  <p>Here I have a second confusion! Even if we have a easily-sample-from approximation distributioin, we must use statistical simulation methods to get sample from. Or even if the sample generator is a Neural Network as in GANs, we must as well sample from a uniform distribution as latent code (input/initialization) to the Neural Net.</p>

  <ol>
    <li>Is this statement true?</li>
    <li>If true,how does this simulation methods actually implemented? [TO-DO: understand VI in Bayesian mixture of Gaussian, see Blei’s note]</li>
  </ol>
</blockquote>

<p>As a fact, easing sampling by limiting expressibility of Q can result in poor approximations. Can we preserve both easy sampling and expressibility? Yes, we can use ideas from GANs to learn <a href="https://arxiv.org/abs/1610.03483">implicit generative model</a>! The relaxation from explicit Q to implicit Q is remarkable. The difference between explicit and implicit is whether we can directly plug in one sample and calculate its prob. density. In implicit models, we cannot.</p>

<p>In the following sub section, I will present the way to transform  $ \mathcal{O}(\theta_Q) $ to suitable forms for GAN-like training.</p>

<h2 id="reduction">Reduction</h2>

<p>The motivation all starts from our willing to expressing approximation distribution Q implicitly, here by using a Feed Forword neural network with initialization random samples from a uniform distribution.</p>

<p>We denote the implicit generative model <script type="math/tex">FFNN(\cdot)</script>, and weight <script type="math/tex">\mathbb{w}</script> for the BLR is sampled from this FFNN, i.e. <script type="math/tex">\mathbb{w} \thicksim FFNN(z), z \thicksim U(\cdot)</script>, where <script type="math/tex">z</script> is sampled from uniform distribution <script type="math/tex">U(\cdot)</script>. Within the framework of GANs, we also call the FFNN as a generator D.</p>

<p>Now, we have a random sample generator which is untrained! Sampling from it is as simple as generating uniformly distributed samples. Let us see how this can help compute the objective function <script type="math/tex">\mathcal{O}</script>. (We denote parameters of this FFNN as <script type="math/tex">\theta_G \in \theta_Q</script>) I rewrite the objective below:</p>

<script type="math/tex; mode=display">\mathcal{O(\theta_Q)} = \mathbb{E}_{ \mathbb{w} \thicksim Q(\mathbb{w}) } log \frac{ Q(\mathbb{w}) }{ P(\mathbb{w}) } - \mathbb{E}_{ \mathbb{w} \thicksim Q(\mathbb{w}) } { log P(\mathcal{D} \vert \mathbb{w}) }</script>

<p>There are two terms in this objective:</p>

<ol>
  <li><strong>Expectation of log prob. ratio w.r.t. <script type="math/tex">\mathbb{w} \thicksim Q</script>.</strong> Since Q is parameterized as FFNN, drawing samples of w is easy. Suppose we draw some samples as <script type="math/tex">\{ \mathbb{w}_i \}_{i=1}^{M}</script>, monte carlo methods can be used as an estimate of this expectation, as well its gradient. For every $ \mathbb{w}_i $, <script type="math/tex">P(\mathbb{w_i})</script> is easy to compute, but we do not have explicit prob. value of <script type="math/tex">Q(\mathbb{w})</script>. <u>So this is a issue to work out!</u></li>
  <li><strong>Expectation of log evidence w.r.t. <script type="math/tex">\mathbb{w} \thicksim Q</script>.</strong> As stated in 1, easy to get samples. The term, <script type="math/tex">log P(\mathcal{D} \vert \mathbb{w}) = log \Pi P(y_i \vert \mathbb{w}; x_i, b) = \Sigma log p_i^{\mathbb{1}[y_i=1]} (1 - p_i)^{\mathbb{1}[y_i=0]}</script>, is trivial to compute as well (unless number of data points is huge!).</li>
</ol>

<p>So we should only solve the computation of prob. ratio <script type="math/tex">\frac{ Q(\mathbb{w}) }{ P(\mathbb{w}) }</script>.</p>

<p>It is <strong>very creative</strong> (from my current viewpoint) to think of the computation of this density ratio of two distributions within the framework of classification. That is, we can unify two densities under one classification problem, i.e. <strong>whether the sample x is from Q or P</strong>. Now, let us derive the classification approach to density ratio estimation.</p>

<p>Assume that <script type="math/tex">P(\mathbb{w}, l)</script> is a joint probability over $ \mathbb{w} $ and <script type="math/tex">l \in \{ -1, 1 \}</script>, a class label (indicator of which underlying distribution $ \mathbb{w} $ comes from). We can factorize <script type="math/tex">P(\mathbb{w}, l)</script> in two ways:</p>

<script type="math/tex; mode=display">P(\mathbb{w}, l) = P(\mathbb{w} \vert l) P(l) = P(l \vert \mathbb{w}) P(\mathbb{w})</script>

<p>Here, the conditional probability of <script type="math/tex">\mathbb{w}</script> given label <script type="math/tex">l</script> means P or Q when <script type="math/tex">l</script> is 1 or -1. So for each value of <script type="math/tex">l</script>, we can write down two equations:</p>

<script type="math/tex; mode=display">P(\mathbb{w} \vert l=1) P(l = 1) = P(l=1 \vert \mathbb{w}) P(\mathbb{w})</script>

<script type="math/tex; mode=display">P(\mathbb{w} \vert l=-1) P(l = -1) = P(l=-1 \vert \mathbb{w}) P(\mathbb{w})</script>

<p>Since we want to compute Q/P, so we can divide <strong>lhs</strong> and <strong>rhs</strong> of these two equations respectively and get:</p>

<script type="math/tex; mode=display">\frac{P(\mathbb{w} \vert l=1)}{P(\mathbb{w} \vert l=-1)} \cdot \frac{P(l=1)}{P(l=-1)} = \frac{P(l=1 \vert \mathbb{w})}{P(l=-1 \vert \mathbb{w})}</script>

<p>We know so:</p>

<script type="math/tex; mode=display">\frac{Q(\mathbb{w})}{P(\mathbb{w})} = \frac{P(l=-1)}{P(l=1)} \cdot \frac{P(l=1 \vert \mathbb{w})}{P(l=-1 \vert \mathbb{w})}</script>

<p>Most of time, we don’t know whose sample frequency is larger, so we assume equal frequency of choosing Q and P for $ \mathbb{w} $’s generation. This result in: <script type="math/tex">P(l=1) = P(l=-1) = \frac{1}{2}</script>. And moreover:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{Q(\mathbb{w})}{P(\mathbb{w})} 
&= \frac{P(l=1 | \mathbb{w})}{P(l=-1 | \mathbb{w})} \\
&= \frac{P(l=1 | \mathbb{w})}{1 - P(l=1 | \mathbb{w})}
\end{align} %]]></script>

<p>Then we can use another model to parameterize <script type="math/tex">P(l=1 \vert \mathbb{w})</script>, and ensure that it can really discriminate between $ \mathbb{w} $ sampled from Q and P. More specific, when given samples sampled from <script type="math/tex">Q</script>, the discriminator should output a probability close to 1, otherwise the probability should be close to 0.</p>

<p>This leads to our design of a discriminator D parameterized by <script type="math/tex">\theta_D \in \theta_Q</script> and another objective, with learning which can ensure the approximate accuracy of estimating <script type="math/tex">P(l=1 \vert \mathbb{w})</script>.</p>

<p>This leads to our design of a discriminator D parameterized by <script type="math/tex">P(l=1\vert \mathbb{w})</script>, and another objective, with learning which can ensure the approximate accuracy of estimating. Specifically, we can use another FFNN with parameter <script type="math/tex">\theta_D</script> to specify the discriminator. That is what we will do in implementation.</p>

<p>Till now, we have finished parameterizing our learning objective <script type="math/tex">\mathcal{O}(\theta_Q)</script> by: <strong>a).</strong> an implicit generative model G to sample <script type="math/tex">\mathbb{w}</script>, <strong>b).</strong> a discriminator D with an auxiliary objective to help density ratio estimation (we use G to substitute FFNN):</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
      \mathcal{O}(\theta_Q) &= \mathbb{E}_{\mathbb{w} \thicksim G} log \frac{D(\mathbb{w})}{1 - D(\mathbb{w})} + \mathbb{E}_{\mathbb{w} \thicksim G} log P(\mathcal{D} | \mathbb{w}) \\
                            &= \mathbb{E}_{z \thicksim U(\cdot)} log \frac{D(G(z))}{1 - D(G(z))} + \mathbb{E}_{z \thicksim U(\cdot)} log P(\mathcal{D} | G(z)) \\
\end{align} %]]></script>

<script type="math/tex; mode=display">\text{Auxiliary}: \mathcal{O}(\theta_D) = \mathbb{E}_{\mathbb{w} \thicksim P(\mathbb{w})} log D(\mathbb{w}) + \mathbb{E}_{z \thicksim U(\cdot)} log (1 - D(G(z))) \</script>

<blockquote>
  <p><b>Comment.</b> I wonder whether my derivation is correct, since it is different from Ferenc’s. I took a look into Ferenc’s <a href="https://gist.github.com/fhuszar/a597906e994523a345744dc226f48f2d">ipython Notebook implementation</a> and found that the code is according to his definition of the discriminator’s loss. I am still working on an explanation.</p>
</blockquote>


</div>
</div>
<div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 col-sm-10 col-sm-offset-1">
        <hr style="margin-top: 50px; margin-bottom: 50px;" />

<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
        //var disqus_developer = 1; // Comment out when the site is live
    var disqus_config = function () {
            this.page.url = "http://tsong.me/blog/variational-posterior-estimatioin-via-GANs/";  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = "/blog/variational-posterior-estimatioin-via-GANs/"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };

    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = 'https://epsilon-lee.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

    </div>
</div>
</div>



<footer style="margin-top: 0px;">
    <div class="container" style="margin-top: 25px; margin-bottom: 20px;">
        <hr style="margin-top: 25px; margin-bottom: 25px;" />
        <p style="text-align: center; font-size: 14px;">
            © 2017 •
            <a href="">epsilon-lee.github.io</a> •
            <a href="" target="_top">epsilonlee.green@gmail.com</a>
        </p>
	<p style="text-align: center; font-size: 14px;">
	    Theme from <a href="http://tsong.me">tsong.me</a>
	</p>
    </div>
</footer>


<script src="//code.jquery.com/jquery-1.10.2.min.js"></script>
<script src="/public/js/bootstrap.min.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68764449-3', 'auto');
    ga('send', 'pageview');

</script>
</body>
</html>
